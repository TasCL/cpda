# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Compute Summed Log-likelihood for a Gaussian Distribution
#'
#' This is a wrapper function to approximate a Gaussian distribution, using
#' KDE-FFT method. To retrieve more outputs, use \code{logLik_norm2}.
#'
#' \code{logLik_norm2} is identical to \code{logLik_norm}, except returning 
#' four elements:
#' 
#' \itemize{
#' \item \bold{\emph{LL}}, summed, logged likelihood. This is the same as the 
#' return value from \code{logLik_plba}. 
#' \item \bold{\emph{PDF}}, a numeric vector storing \emph{logged} 
#' probability densities for individual data point.
#' \item \bold{\emph{z}}, a numeric vector storing centre points of the 
#' simulated histogram (i.e., grid centre)
#' \item \bold{\emph{PDF_hist}} a numeric vector stoing the count of simulated
#' data point in each bin 
#' } 
#' @param object a vector storing empirical data
#' @param pVec parameter vector storing mean and standard deviation
#' @param ns number of simulations. Default is 1e5.
#' @param h KDE bandwidth. If not input been enter, the default is 
#' Sliverman's rule of thumb; otherwise the function uses the input from
#' the user; 
#' @param m a multiplier to adjust proportationally h. Default is 0.8
#' @param p a precision parameter defines the number of grid as power of 2.
#' Default value is 10 (i.e., 2^10).
#' @return Log-likelihood; plus PDF, grid centers, and PDF_hist
#' @export
#' @examples
#' pVec <- c(mu=5, sigma=1)
#' y    <- sort(rnorm(1e5, pVec[1], pVec[2]))
#'
#' ll1 <- logLik_norm(y, pVec, 1e5)
#' ll2 <- logLik_norm2(y, pVec, 1e5)
#' str(ll1); str(ll2)
#'
#' plot(ll2$z, ll2$PDF_hist, type="l", lty=2,
#' main="Normal Distribution",xlab="x",ylab="L(x|theta)")
#' lines(y, exp(ll2$PDF), col="red", lwd = 1.5)
#'
logLik_norm <- function(object, pVec, ns = 1e5L, h = 0, m = 0.8, p = 10) {
    .Call('cpda_logLik_norm', PACKAGE = 'cpda', object, pVec, ns, h, m, p)
}

#' @rdname logLik_norm
#' @export
logLik_norm2 <- function(object, pVec, ns = 1e5L, h = 0, m = 0.8, p = 10) {
    .Call('cpda_logLik_norm2', PACKAGE = 'cpda', object, pVec, ns, h, m, p)
}

#' Compute Summed Log-likelihood for a pLBA Model
#'
#' This is a wrapper function to approximate a pLBA distribution, using
#' KDE-FFT method. To retrieve more outputs, use \code{logLik_plba2}.
#'
#' \code{logLik_plba2} is identical to \code{logLik_plba}, except returning 
#' four elements:
#' 
#' \itemize{
#' \item \bold{\emph{LL}}, summed, logged likelihood. This is the same as the 
#' return value from \code{logLik_plba}. 
#' \item \bold{\emph{PDF}}, a numeric vector storing \emph{logged}  
#' probability densities for individual data point.
#' \item \bold{\emph{z}}, a numeric vector storing centre points of the 
#' simulated histogram (i.e., grid centre)
#' \item \bold{\emph{PDF_hist}} a numeric vector stoing the count of simulated
#' data point in each bin 
#' } 
#' 
#' @param object a matrix storing empirical choice RT data. First column must
#' stores choices and second column stores RTs in seconds.
#' @param pVec a vector storing pLBA model parameters. The sequence is 
#' critical. it is A1, A2, b1, b2, v1, v2, w1, w2, sv1, sv2, sw1, sw2,
#' rD, swt, and t0. 
#' @param ns number of simulations. Default is 1e5.
#' @param h KDE bandwidth. If not input been enter, the default is 
#' Sliverman's rule of thumb; otherwise the function uses the input from
#' the user; 
#' @param m a multiplier to adjust proportationally h. Default is 0.8
#' @param p a precision parameter defines the number of grid as power of 2.
#' Default value is 10 (i.e., 2^10).
#' @return a summed, logged likelihood across trials and accumulators. 
#' \code{logLik_plba2} returns three more elements.
#' @export
#' @examples  
#' ###################
#' ## Example 1     ##
#' ###################
#' ## I demonstrate how to use the build-in logLik_plba to calculate
#' ## pLBA densities. set.seed(123) is to produce the same result.
#' rm(list=ls())
#' pVec <- c(A1=1.51, A2=1.51, b1=2.7, b2=2.7, v1=3.32, v2=2.24,
#'             w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.31, 
#'             swt=0.5, t0=0.08)
#'   
#' data(lba)
#' d$Response <- ifelse(d$Response==0, 1, 2)
#' dMat <- data.matrix(d); head(dMat)
#' n <- 1e5
#'   
#' set.seed(123)
#' ll0 <- cpda::logLik_plba(dMat, pVec, 1e5, h=h, m=1); ll0
#'       
#' set.seed(123)
#' llList <- cpda::logLik_plba2(dMat, pVec, 1e5, h=h, m=1); str(llList)
#' ## List of 4
#' ## $ LL      : num 327
#' ## $ PDF     : num [1:1000, 1:4] 1 1 1 1 1 1 1 1 1 1 ...
#' ## $ z       : num [1:2048, 1] 0.13 0.135 0.14 0.146 0.151 ...
#' ## $ PDF_hist: num [1:2048, 1] 0 0 0 0 0 ...
#'         
#' ###################
#' ## Example 2     ##
#' ###################
#' ## Secondly, I demonstrate use rplba2 and logLik_fft to produce identical 
#' ## result
#' rm(list=ls())
#' x <- cbind(rep(1:2,each=100),rep(seq(.5,2,length.out=100),2))
#' pVec <- c(A1=1.51, A2=1.51, b1=2.7, b2=2.7, v1=3.32, v2=2.24,
#'             w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.31, 
#'             swt=0.5, t0=0.08)
#' dt1 <- x[x[,1]==1,2] - pVec[15]
#' dt2 <- x[x[,1]==2,2] - pVec[15]
#' 
#' set.seed(123)
#' n <- 1e5
#' samp <- cpda::rplba2(n, pVec); head(samp)
#' dt1_ <- samp[samp[,1]==1,2] - pVec[15]
#' dt2_ <- samp[samp[,1]==2,2] - pVec[15]
#' logLik_fft(dt1, dt1_) + logLik_fft(dt2, dt2_)
#'   
#' set.seed(123)
#' cpda::logLik_plba(x, pVec)
#'   
#' fft1 <- cpda::logLik_plba2(x, pVec)
#' str(fft1)
#' 
#' ## choice RT PDF
#' tmp0 <- fft1$PDF[fft1$PDF[,1] == 1, 2]
#' tmp1 <- sort(x[x[,1]==1,2])
#' all(tmp0==tmp1)
#'   
#' tmp3 <- fft1$PDF[fft1$PDF[,1] == 2,2]
#' tmp4 <- sort(x[x[,1]==1,2])
#' all(tmp3==tmp4)
#'               
logLik_plba <- function(object, pVec, ns = 1e5L, h = 0, m = 0.8, p = 10) {
    .Call('cpda_logLik_plba', PACKAGE = 'cpda', object, pVec, ns, h, m, p)
}

#' @rdname logLik_plba
#' @export
logLik_plba2 <- function(object, pVec, ns = 1e5L, h = 0, m = 0.8, p = 10) {
    .Call('cpda_logLik_plba2', PACKAGE = 'cpda', object, pVec, ns, h, m, p)
}

#' Compute Summed Log-likelihood for a LBA Model
#'
#' This is a wrapper function to approximate the densities of a LBA model, 
#' using \code{logLik_fft}. To retrieve more outputs, use \code{logLik_lba2}.
#' 
#' \code{logLik_lba2} is identical to \code{logLik_lba}, except the former 
#' returns three more elements: 
#'  
#' \itemize{
#' \item \bold{\emph{LL}}, summed, logged likelihood. This is the same as the 
#' return value from \code{logLik_lba}. 
#' \item \bold{\emph{PDF}}, a numeric vector storing logged probability 
#' densities for individual data point.
#' \item \bold{\emph{z}}, a numeric vector storing centre points of the 
#' simulated histogram (i.e., grid centre)
#' \item \bold{\emph{PDF_hist}} a numeric vector stoing the count of simulated
#' data point in each bin 
#' } 
#'
#' @param object a matrix storing empirical choice RT data. First column must
#' be choices (1 & 2) and second column must bve RTs in seconds.
#' @param pVec LBA parameter vector. The sequence is critical. It is b1, b2, 
#' A1, A2, mu1, mu2, sigma1, sigma2, t01, and t02. 1 and 2 stand for 
#' accumulator 1 and 2, respectively.  
#' @param ns number of simulations. Default is 1e5.
#' @param h KDE bandwidth. If not given, the default \code{h} is 
#' Sliverman's rule of thumb; otherwise the function uses the input from
#' the user; 
#' @param m a multiplier to adjust proportationally h. Default is 0.8
#' @param p a precision parameter defines the number of grid as power of 2.
#' Default value is 10 (i.e., 2^10).
#' @return a summed, logged likelihood across trials and accumulators. 
#' \code{logLik_plba2} returns three more elements.
#' @export
#' @examples  
#' ## Demo identical outputs from manually building rlba and logLik_fft, 
#' ## comparing to logLik_lba 
#' 
#' ## First retrieve example data set
#' data(lba)  
#' d$R <- ifelse(d$Response==0, 1, 2)  ## convert 0 & 1 accumulator to 1 & 2
#' dMat <- data.matrix(data.frame(R=d$R, RT=d$ResponseTime))
#' head(dMat)
#'  
#' ## LBA parameter vector. The sequence is critical. 
#' pVec <- c(b1=1, b2=1, A1=.5, A2=.5, mu1=2.4, mu2=1.6, sigma1=1, sigma2=1.2,
#'           t01=.5, t02=.5)
#'            
#' set.seed(123)  ## make sure using identical simulations
#' samp <- cpda::rlba(1e5, pVec); head(samp)
#' h    <- 0.8*bw.nrd0(samp[,2]); h
#' 
#' ## logLik_lba simulates internally, so set.seed ahead to make sure using
#' ## identical simulations
#' set.seed(123)  
#' tmp0 <- cpda::logLik_lba(dMat, pVec, 1e5, h, 1); tmp0 ## -3496.88
#' 
#' ## Manually calculate empirical DTs for accumulator 1 and accumualtor 2
#' dt1  <- sort(dMat[dMat[,1] == 1, 2]) - pVec[9]
#' dt2  <- sort(dMat[dMat[,1] == 2, 2]) - pVec[10]
#' dt1_ <- sort(samp[samp[,1] == 1, 2]) - pVec[9]
#' dt2_ <- sort(samp[samp[,1] == 2, 2]) - pVec[10]
#'     
#' ## Calculating log-likelihoods separately for each accumulator
#' ll1 <- cpda::logLik_fft(dt1, dt1_, h, 1); ll1
#' ll2 <- cpda::logLik_fft(dt2, dt2_, h, 1); ll2
#' print(ll1+ll2) ## -3496.88
#'  
logLik_lba <- function(object, pVec, ns = 1e5L, h = 0, m = 0.8, p = 10) {
    .Call('cpda_logLik_lba', PACKAGE = 'cpda', object, pVec, ns, h, m, p)
}

#' @rdname logLik_lba
#' @export
logLik_lba2 <- function(object, pVec, ns = 1e5L, h = 0, m = 0.8, p = 10) {
    .Call('cpda_logLik_lba2', PACKAGE = 'cpda', object, pVec, ns, h, m, p)
}

#' Generate Random Choice Response Times Using LBA Model
#'
#' This function uses two-accumulator LBA model to generate random choice RTs.
#' 
#' \itemize{
#' \item \bold{\emph{b1}} response threshold for accumulator 1. 
#' \item \bold{\emph{b2}} response threshold for accumulator 2. 
#' \item \bold{\emph{A1}} starting point interval for accumulator 1. 
#' \item \bold{\emph{A2}} starting point interval for accumulator 2. 
#' \item \bold{\emph{mu1}} drift rate for accumulator 1.
#' \item \bold{\emph{mu2}} drift rate for accumulator 2. 
#' \item \bold{\emph{sigma1}} drift rate standard deviation for accumulator 1.
#' \item \bold{\emph{sigma2}} drift rate standard deviation for accumulator 2.
#' \item \bold{\emph{t01}} non-decision time for accumulator 1. 
#' \item \bold{\emph{t02}} non-decision time for accumulator 2. 
#' }
#'
#' @param n number of observations. Must be an integer
#' @param pVec a two-accumulator LBA parameter vector. The sequence is 
#' critical. It is, b1, b2, A1, A2, mu1, mu2, sigma1, sigma2, t01, and t02.
#' @return A matrix. First column stores choices and second column stores RTs 
#' in seconds
#' @export
#' @examples
#' n    <- 10
#' pVec <- c(b1=1, b2=1, A1=.5, A2=.5, mu1=2.4, mu2=1.6, sigma1=1, sigma2=1.2,
#'           t01=.5, t02=.5)
#' dat1 <- cpda::rlba(n, pVec)
#' str(dat1)
#' summary(dat1)
#' 
#' ## Compare to rtdists
#' ## dat2 <- rtdists::rLBA(n, A=0.5, b=1, t0 = 0.5, mean_v=c(2.4, 1.6), 
#' ## sd_v=c(1,1.2))
#' ## str(dat2)
#' ## summary(dat2)
#' 
rlba <- function(n, pVec) {
    .Call('cpda_rlba', PACKAGE = 'cpda', n, pVec)
}

#' @rdname rplba
#' @export
rplba1 <- function(n, pVec) {
    .Call('cpda_rplba1', PACKAGE = 'cpda', n, pVec)
}

#' @rdname rplba
#' @export
rplba2 <- function(n, pVec) {
    .Call('cpda_rplba2', PACKAGE = 'cpda', n, pVec)
}

#' Generate Random Choice Response Times using pLBA Model
#'
#' This function uses two-accumulator piecewise LBA model to generate random 
#' choice RTs. There are 3 variants: \code{rplba}, \code{rplba1}, and 
#' \code{rplba2}. Each of them has a corresponding R version,
#' \code{rplbaR}, \code{rplbaR1}, and \code{rplbaR2}, for the purpose of 
#' speed testing. Because the difference of random number generators in C and 
#' R, they do not generate exactly identical RTs.  When generating large 
#' enough observations, the distributions generated by R and C will match.
#' 
#' The main function \code{rplba} implements a more flexible  
#' version of pLBA random number generator than the other two. It uses the  
#' following parameterisation (order matter):
#'  
#' \itemize{
#' \item \bold{\emph{A1}} accumulator 1 start-point upper bound. \code{A} is  
#' the upper bound of the interval \code{[0, A]}, which is used by an uniform 
#' distribution to generate a start-point. Average amount of 
#' prior evidence (i.e., before accumulation process even begins) across trials
#' is \code{A/2}.
#' \item \bold{\emph{A2}} accumulator 2 start-point upper bound.
#' \item \bold{\emph{B1}} accumulator 1 traveling distance. Note this is not 
#' a decision threshold!. LBA convention denotes decision threshold/caution as 
#' b (lowercase) and traveling distance as B (uppercase). \code{B=b-A} is 
#' the traveling distance, and \code{b-A/2} is a measure of average 
#' \emph{decision caution}.
#' \item \bold{\emph{B2}} accumulator 2 traveling distance.
#' \item \bold{\emph{C1}} the amount of traveling distance change for 
#' accumulator 1 at the stage 2. 
#' \item \bold{\emph{C2}} the amount of traveling distance change for 
#' accumulator 2 at the stage 2.
#' \item \bold{\emph{v1}} accumulator 1 drift rate, stage 1
#' \item \bold{\emph{v2}} accumulator 2 drift rate, stage 1
#' \item \bold{\emph{w1}} accumulator 1 drift rate, stage 2
#' \item \bold{\emph{w2}} accumulator 2 drift rate, stage 2
#' \item \bold{\emph{sv1}} accumulator 1 drift rate standard deviation, 
#' stage 1.
#' \item \bold{\emph{sv2}} accumulator 2 drift rate standard deviation, 
#' stage 1.
#' \item \bold{\emph{sw1}} accumulator 1 drift rate standard deviation, 
#' stage 2.
#' \item \bold{\emph{sw2}} accumulator 2 drift rate standard deviation, 
#' stage 2.
#' \item \bold{\emph{rD}} the delay duration while stage 1 drift rate switches
#' to stage 2 drift rate 
#' \item \bold{\emph{tD}} the delay duration while stage 1 threshold switches
#' to stage 2 threshold 
#' \item \bold{\emph{swt}} switch time, usually determined by experimental 
#' design. 
#' \item \bold{\emph{t0}} non-decision time in second. 
#' }
#' 
#' \code{rplba1} uses the following parameterisation: 
#' 
#' \itemize{
#' \item \bold{\emph{A}} a common start-point interval for both accumulators. 
#' \item \bold{\emph{b}} a common response threshold for both accumulators.  
#' \item \bold{\emph{v1}} accumulator 1 drift rate, stage 1
#' \item \bold{\emph{v2}} accumulator 2 drift rate, stage 1
#' \item \bold{\emph{w1}} accumulator 1 drift rate, stage 2
#' \item \bold{\emph{w2}} accumulator 2 drift rate, stage 2
#' \item \bold{\emph{sv}} a common standard deviation for both accumulators
#' \item \bold{\emph{rD}} a delay period while drift rate switch to a 
#' second stage process   
#' \item \bold{\emph{swt}} switch time, usually determined by experimental 
#' design
#' \item \bold{\emph{t0}} non-decision time in second. 
#' }
#' 
#' \code{rplba2} uses the following parameterisation: 
#' 
#' \itemize{
#' \item \bold{\emph{A1}} start-point interval of the accumulator 1. 
#' \item \bold{\emph{A2}} start-point interval of the accumulator 2. 
#' \item \bold{\emph{b1}} accumulator 1 response threshold. 
#' \item \bold{\emph{b2}} accumulator 2 response threshold. 
#' \item \bold{\emph{v1}} accumulator 1 drift rate, stage 1
#' \item \bold{\emph{v2}} accumulator 2 drift rate, stage 1
#' \item \bold{\emph{w1}} accumulator 1 drift rate, stage 2
#' \item \bold{\emph{w2}} accumulator 2 drift rate, stage 2
#' \item \bold{\emph{sv1}} the standard deviation of accumulator 1 drirt rate
#' during stage 1. 
#' \item \bold{\emph{sv2}} the standard deviation of accumulator 2 drirt rate
#' during stage 1. 
#' \item \bold{\emph{sw1}} the standard deviation of accumulator 1 drirt rate
#' during stage 2. 
#' \item \bold{\emph{sw2}} the standard deviation of accumulator 2 drirt rate
#' during stage 2. 
#' \item \bold{\emph{rD}} a delay period while drift rate switch to a 
#' second stage process   
#' \item \bold{\emph{swt}} switch time, usually determined by experimental 
#' design
#' \item \bold{\emph{t0}} non-decision time in second. 
#' }
#'
#' @param n number of observations. Must be an integer 
#' @param pVec a numeric vector storing pLBA model parameters. The sequence is
#' critical. See details for the sequence. 
#' @return A \code{n x 2} matrix with a first column storing choices and second 
#' column storing response times.
#' @export
#' @examples
#' ################
#' ## Example 1  ##
#' ################
#' pVec3.1 <- c(A1=1.51, A2=1.51, B1=1.2, B2=1.2, C1=.3, C2=.3, v1=3.32, 
#'              v2=2.24, w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.1,
#'              tD=.1, swt=0.5, t0=0.08)
#' pVec3.2 <- c(A1=1.51, A2=1.51, B1=1.2, B2=1.2, C1=.3, C2=.3, v1=3.32, 
#'              v2=2.24, w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.1,
#'              tD=.15, swt=0.5, t0=0.08)
#' pVec3.3 <- c(A1=1.51, A2=1.51, B1=1.2, B2=1.2, C1=.3, C2=.3, v1=3.32, 
#'              v2=2.24, w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.15,
#'              tD=.1, swt=0.5, t0=0.08)
#' 
#' n <- 1e5
#' set.seed(123); system.time(dat5.1 <- cpda::rplbaR(n, pVec3.1))
#' set.seed(123); system.time(dat5.2 <- cpda::rplbaR(n, pVec3.2))
#' set.seed(123); system.time(dat5.3 <- cpda::rplbaR(n, pVec3.3))
#' set.seed(123); system.time(dat6.1 <- cpda::rplba( n, pVec3.1))
#' set.seed(123); system.time(dat6.2 <- cpda::rplba( n, pVec3.2))
#' set.seed(123); system.time(dat6.3 <- cpda::rplba( n, pVec3.3))
#' tmp5.1 <- data.frame(choice=factor(dat5.1[,1]), rt=dat5.1[,2])
#' tmp5.2 <- data.frame(choice=factor(dat5.2[,1]), rt=dat5.2[,2])
#' tmp5.3 <- data.frame(choice=factor(dat5.3[,1]), rt=dat5.3[,2])
#' tmp6.1 <- data.frame(choice=factor(dat6.1[,1]), rt=dat6.1[,2])
#' tmp6.2 <- data.frame(choice=factor(dat6.2[,1]), rt=dat6.2[,2])
#' tmp6.3 <- data.frame(choice=factor(dat6.3[,1]), rt=dat6.3[,2])
#'   
#' tmp5.1$fun <- "R"
#' tmp5.2$fun <- "R"
#' tmp5.3$fun <- "R"
#' tmp6.1$fun <- "C"
#' tmp6.2$fun <- "C"
#' tmp6.3$fun <- "C"
#' 
#' tmp5.1$vec <- "1"
#' tmp5.2$vec <- "2"
#' tmp5.3$vec <- "3"
#' tmp6.1$vec <- "1"
#' tmp6.2$vec <- "2"
#' tmp6.3$vec <- "3"
#' 
#' df <- rbind(tmp5.1, tmp5.2, tmp5.3, tmp6.1, tmp6.2, tmp6.3)
#' df$fun <- factor(df$fun)
#'         
#' ## Show R and C functions produce almost identical distributions        
#' \dontrun{ 
#' ## Set up a colour palette 
#' cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2",
#'         "#D55E00", "#CC79A7")
#'         
#' require(ggplot2)
#' ggplot(data=df, aes(x = rt, fill=fun, color=fun)) +
#'   geom_density(alpha=0.2) +
#'   facet_grid(vec~ choice) +
#'   scale_fill_manual(values=cb)
#'   
#' ## Or you can use lattice or base graphics  
#' require(lattice)
#' histogram( ~rt | vec+choice+fun, data=df, breaks="fd", type="density", 
#'            xlab="Response Time (s)", 
#'            panel=function(x, ...) {
#'                  panel.histogram(x, ...)
#'                  panel.densityplot(x, darg=list(kernel="gaussian"),...)
#'   })
#' }
#'              
#' par(mfrow=c(3,2))
#' hist(tmp5.1[tmp5.1$choice==1,"rt"], breaks="fd", col="gray", freq=FALSE, 
#'        xlab="RT (s)", main="pLBA-Choice 1")
#' lines(density(tmp6.1[tmp6.1$choice==1,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'   
#' hist(tmp5.1[tmp5.1$choice==2,"rt"], breaks="fd", col="gray", freq=FALSE, 
#'        xlab="RT (s)", main="pLBA-Choice 2")
#' lines(density(tmp6.1[tmp6.1$choice==2,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'   
#' #############
#' hist(tmp5.2[tmp5.2$choice==1,"rt"], breaks="fd", col="gray", freq=FALSE, 
#'        xlab="RT (s)", main="pLBA-Choice 1")
#' lines(density(tmp6.2[tmp6.2$choice==1,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'     
#' hist(tmp5.2[tmp5.2$choice==2,"rt"], breaks="fd", col="gray", freq=FALSE, 
#'          xlab="RT (s)", main="pLBA-Choice 2")
#' lines(density(tmp6.2[tmp6.2$choice==2,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'     
#' #############
#' hist(tmp5.3[tmp5.3$choice==1,"rt"], breaks="fd", col="gray", freq=FALSE, 
#'          xlab="RT (s)", main="pLBA-Choice 1")
#' lines(density(tmp6.3[tmp6.3$choice==1,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'       
#' hist(tmp5.3[tmp5.3$choice==2,"rt"], breaks="fd", col="gray", freq=FALSE, 
#'            xlab="RT (s)", main="pLBA-Choice 2")
#' lines(density(tmp6.3[tmp6.3$choice==2,"rt"]), col="red", lty="dashed",  lwd=1.5)
#' par(mfrow=c(1,1))
#' 
#' ################
#' ## Example 2  ##
#' ################
#' pVec1 <- c(A=1.51, b=2.7, v1=3.32, v2=2.24,  w1=1.51,  w2=3.69,  
#'            sv=1, rD=0.31, swt=0.5, t0=0.08)
#'  
#' pVec2 <- c(A1=1.51, A2=1.51, b1=2.7, b2=2.7, v1=3.32, v2=2.24,
#'            w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.31, 
#'            swt=0.5, t0=0.08)
#'            
#' system.time(dat1 <- cpda::rplba1( n, pVec1))
#' system.time(dat2 <- cpda::rplba2( n, pVec2))
#' system.time(dat3 <- cpda::rplbaR1(n, pVec1))
#' system.time(dat4 <- cpda::rplbaR2(n, pVec2))
#' 
#' tmp1 <- data.frame(choice=factor(dat1[,1]), rt=dat1[,2])
#' tmp2 <- data.frame(choice=factor(dat2[,1]), rt=dat2[,2])
#' tmp3 <- data.frame(choice=factor(dat3[,1]), rt=dat3[,2])
#' tmp4 <- data.frame(choice=factor(dat4[,1]), rt=dat4[,2])
#' tmp1$fun <- "rplba1"
#' tmp2$fun <- "rplba2"
#' tmp3$fun <- "rplba1-R"
#' tmp4$fun <- "rplba2-R"
#' tmp0 <- rbind(tmp1, tmp2, tmp3, tmp4)
#' tmp0$fun <- factor(tmp0$fun)
#'   
#' \dontrun{   
#' require(ggplot2)
#' ggplot(data = tmp0, aes(x = rt, fill=fun, color=fun)) +
#'     geom_density(alpha=0.2) +
#'     facet_grid(.~ choice) +
#'     scale_fill_manual(values=cb)
#' }
#'     
rplba <- function(n, pVec) {
    .Call('cpda_rplba', PACKAGE = 'cpda', n, pVec)
}

#' Compute Summed Log-Likelihood Using KDE-FFT 
#'
#' This function uses KDE-FFT method to approximate probability density. 
#' \code{logLik_fft} returns only one scalar value, which is summed, logged 
#' likelihood. Use \code{logLik_fft2} to retrieve three additional elements: 
#' \emph{PDF}, \emph{z} and \emph{PDF_hist}. See \code{\link{logLik_fft2}} for 
#' further details.  
#'
#' @param y a scalar or vector storing empirical data.
#' @param yhat a scalar or vector storing simulated data (e.g., 
#' \code{rnorm(100)}).
#' @param h the bandwidth of kernel density estimation. If not given, 
#' \code{logLik_fft} will detect the default, \code{h==0} and accordingly 
#' convert it to Sliverman's rule of thumb; otherwise the function uses 
#' bandwidth entered by the user; 
#' @param m a multiplier to adjust \code{h} proportationally. Default is 0.8. 
#' If one wish not adjust bandwidth, s/he has to enter \code{m=1}. 
#' @param p a precision parameter defines the number of grid as power of 2.
#' Default value is 10 (i.e., ngrid==2^10). 
#' @return Summed log-likelihood
#' @references Holmes, W. (2015). A practical guide to the Probability Density
#' Approximation (PDA) with improved implementation and error characterization.
#' \emph{Journal of Mathematical Psychology}, \bold{68-69}, 13--24,
#' doi: http://dx.doi.org/10.1016/j.jmp.2015.08.006.
#' @seealso
#' \code{\link{bw.nrd}}, \code{\link{logLik_fft2}}, 
#' \code{\link{bandwidth.nrd}}.
#' 
#' @export
#' @examples
#' ## See logLik_fft2 for more examples
#' ## Use piecewise LBA data as an example
#' data(lba)
#' logLik_fft(plba$DT1, plba$eDT1)
#' logLik_fft(plba$DT2, plba$eDT2)
logLik_fft <- function(y, yhat, h = 0, m = 0.8, p = 10) {
    .Call('cpda_logLik_fft', PACKAGE = 'cpda', y, yhat, h, m, p)
}

#' Compute Summed Log-Likelihood 
#'
#' \code{logLik_fft2} uses an identical algorithm as \code{logLik_fft}, but
#' return more elements. Differing from \code{logLik_pw}, \code{logLik_fft2} 
#' and \code{logLie_fft},  
#' \enumerate{
#' \item takes Monte Carlo simulations,
#' \item transforms them to spectral domain using FFT,
#' \item applies a standard Gaussian kernel to smooth them,
#' \item transforms them back to signal domain and
#' \item interpolates linearly the simulation histogram to the observed data 
#' points to obtain estimated likelihoods.
#' }
#'  
#' \code{logLik_fft2} returns four elements:
#' \itemize{
#' \item \bold{\emph{LL}}, summed, logged likelihood. This is identical as the 
#' return value from \code{logLik_fft}. 
#' \item \bold{\emph{PDF}}, a matrix storing individual data point (column 1)
#' and logged probability densities (column 2).
#' \item \bold{\emph{z}}, a vector storing centre points of the 
#' simulated histogram (i.e., grid centre)
#' \item \bold{\emph{PDF_hist}} a vector stoing the count of simulated
#' data point in each histogram bin 
#' } 
#'
#' @param y a scalar or vector storing empirical data.
#' @param yhat a scalar or vector storing simulated data (e.g., 
#' \code{rnorm(100)}).
#' @param h the bandwidth for kernel density estimation. If not given, 
#' \code{logLik_fft} will use Sliverman's rule of thumb
#' @param m a multiplier to adjust \code{h} proportationally. Default is 0.8. 
#' This applies also when the user enters his/her own bandwidth. 
#' @param p a precision parameter defines the number of grid as power of 2.
#' Default value is 10 (i.e., 2^10). 
#' @return A list with 4 elements.
#' @references Holmes, W. (2015). A practical guide to the Probability Density
#' Approximation (PDA) with improved implementation and error characterization.
#' \emph{Journal of Mathematical Psychology}, \bold{68-69}, 13--24,
#' doi: http://dx.doi.org/10.1016/j.jmp.2015.08.006.
#' @seealso
#' \code{\link{logLik_pw}}, \code{\link{logLik_fft}},
#' \code{\link{bw.nrd}}, \code{\link{bandwidth.nrd}}.
#' 
#' @export
#' @examples
#' ###################
#' ## Example 1     ##
#' ###################
#' x <- seq(-3, 3, length.out=100) ## Data
#' samp <- rnorm(1e6)              ## Monte Carlo simulation 
#' h <- 0.8*bw.nrd0(samp)          ## Define bandwidth using R's bw.nrd0
#' 
#' ## First, I demonstrate how to use point-wise logLik
#' ## Note logLik_pw returns log-likelihood.
#' system.time(pw1  <- logLik_pw(x, samp, h=h, m=1))
#' ##   user  system elapsed 
#' ##  3.480   0.120   3.605 
#' 
#' ## Second, I demonstrate how to use KDE-FFT. logLik_fft2 retrieves 
#' ## log-likelihoods for all data point  
#' system.time(fft1 <- logLik_fft2(x, samp, h=h, m=1)[["PDF"]])
#' ##   user  system elapsed 
#' ##  1.056   0.024   1.079 
#' 
#' ## Third, I demonstrate how to build-in routine binding logLik_fft and 
#' ## rnorm to get Gaussian density. Enter ?logLik_norm2 to see help page
#' ## pVec stands for parameter vector. For a Gaussian model, pVec stores mean
#' ## and standard deviation.
#' system.time(fft2 <- logLik_norm2(x, pVec=c(0,1), 1e6, h=h, m=1)[["PDF"]])
#' ##   user  system elapsed 
#' ##  1.304   0.040   1.349  
#' 
#' ## You should get all 4 lines overlaping one another
#' ## the tails may be a bit off.
#' plot(x, pw1,type="l", lty="dotted")
#' lines(x, fft1, col="darkgreen", lty="dashed")
#' lines(x, fft2, col="blue", lty="dotdash")
#' lines(x, dnorm(x, log=TRUE), col="red")
#' 
#' ###################
#' ## Example 2     ##
#' ###################
#' ## Use piecewise LBA data as an example
#' data(lba)
#' logLik_fft(plba$DT1, plba$eDT1)
#' logLik_fft(plba$DT2, plba$eDT2)
#' plbaEg1 <- logLik_fft2(plba$DT1, plba$eDT1)
#' plbaEg2 <- logLik_fft2(plba$DT2, plba$eDT2)
#'
#' str(plbaEg1)
#' ## List of 4
#' ## $ LL      : num 280
#' ## $ PDF     : num [1:695, 1] 0.918 -0.456 0.668 0.872 0.788 ...
#' ## $ z       : num [1:1024, 1] 0.128 0.129 0.13 0.131 0.133 ...
#' ## $ PDF_hist: num [1:1024, 1] 0 0 0 0 0 0 0 0 0 0 ...
#' str(plbaEg2)
#' ## List of 4
#' ## $ LL      : num 45.3
#' ## $ PDF     : num [1:305, 1] 0.6396 -0.1174 0.6178 -1.3723 -0.0273 ...
#' ## $ z       : num [1:1024, 1] 0.121 0.124 0.126 0.129 0.131 ...
#' ## $ PDF_hist: num [1:1024, 1] 0 0 0 0 0 0 0 0 0 0 ...
logLik_fft2 <- function(y, yhat, h = 0, m = 0.8, p = 10) {
    .Call('cpda_logLik_fft2', PACKAGE = 'cpda', y, yhat, h, m, p)
}

#' A simple and fast quantile calculator
#'
#' A C++ quantile function.
#'
#' @param y a data vector
#' @param q nth quantile. Enter proportion, such as .25 or .75.
#' @examples
#' y <- rnorm(100)
#' q <- cquantile(y, .25) 
#' @export
cquantile <- function(y, q) {
    .Call('cpda_cquantile', PACKAGE = 'cpda', y, q)
}

#' Silverman's Rule of Thumb Bandwidth for Kernel Density Estimation
#'
#' A C++ version of Silverman's rule-of-thumb bandwidth. This is similar
#' with R's \code{bw.nrd0(x)}
#'
#' @param y a data vector
#' @param m a multiplier to adjust the SROT proportionally.
#' 
#' @seealso
#' \code{\link{bw.nrd}}, \code{\link{bandwidth.nrd}}.
#' @export
#' @examples
#' data(lba)
#' h <-cpda::bwNRD0(plba$DT1, 0.8)
#' 
bwNRD0 <- function(y, m) {
    .Call('cpda_bwNRD0', PACKAGE = 'cpda', y, m)
}

