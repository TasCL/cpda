# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Prior Log-likelihood
#'
#' This function computes the prior log-likelihood for the given parameter set,
#' using uniform distributions.
#'
#' @param pVec a vector storing pLBA model parameters. The sequence is 
#' critical. It is, A1, A2, v1, v2, t01, t02. 
#' @return a prior log prior likelihood
#' @export
#' @examples
#' logLik_prior(pVec)
#' 
logLik_prior <- function(pVec) {
    .Call('cpda_logLik_prior', PACKAGE = 'cpda', pVec)
}

#' @export
logLik_prior_test <- function(pVec) {
    .Call('cpda_logLik_prior_test', PACKAGE = 'cpda', pVec)
}

#' Generate a Gamma Vector 
#'
#' This is part of DEMC algorithm. \code{gammavec} generates a gamma vector 
#' for element-wise compuation in Armadillo C++.
#' 
#' @param npar number of parameters. 
#' @param gammamult a tuning parameter for gamma mutation. Default value is 2.38.
#' @return a column vector
#' @export
#' @examples
#' pVec <- c(A=1.51, b=2.7, muv1=3.32, muv2=2.24, t_ND=0.08, muw1=1.51,  
#'           muw2=3.69, t_delay=0.31,  sv=1, swt=0.5)
#' gamma <- gammavec(length(pVec), 2.38)
gammavec <- function(npar, gammamult = 2.38) {
    .Call('cpda_gammavec', PACKAGE = 'cpda', npar, gammamult)
}

#' Pick Other Chains Randomly
#'
#' This is part of DEMC algorithm. The function randomly samples \code{n}   
#' chains out of \code{length(chains)} chains, excluding the kth chain.
#' chains.
#'
#' @param k an integer indicating which chain is processed currently. This 
#' must be an integer within the range of 0 to \code{nchain-1} (i.e., C index).
#' No check for errorly using R index, because this is an internal function.
#' @param n the numbers of chain to sample.
#' @param chains a numeric vector of chain index, e.g., 0:24.  
#' @return a column vector
#' @keywords pickchains
#' @export
#' @examples
#' nchain <- 24
#' chainSeq <- (1:24)-1 ## Convert to C index
#' 
#' ## Current processing chain is the fourth chain (index=3) 
#' ## We wish to pick 2 chains out of 24 chains
#' pickchains(3, 2, chainSeq) 
#' 
pickchains <- function(k, n, chains) {
    .Call('cpda_pickchains', PACKAGE = 'cpda', k, n, chains)
}

#' Crossover and Migration Samplers    
#'
#' This is part of DE-MC algorithm (crossover) and Distributed Evolutionary 
#' Monte Carlo (migration). Both samplers propose a set of new parameters. 
#' 
#' @param theta a npar x nchain matrix 
#' @param gamma a gamma vector. 
#' @param k current chain index. Note chain index starts from 0.
#' @param rp ter Braak's (2006) b, setting the range of the uniform 
#' distribution that derives epsilon. This is set at 1e-3.
#' @return a column vector
#' @references ter Braak, C. J. F. (2006). A Markov Chain Monte Carlo version 
#' of the genetic algorithm Differerntial Evolution: Easy Bayesian computing
#' for real parameter spaces. Statistics and Computing, 16, 239â€“249. \cr\cr
#' Hu, B., & Tsui, K.-W. (2005). Distributed evolutionary Monte Carlo with 
#' applications to Bayesian analysis Technical Report Number 1112.
#' @export
#' @examples
#' init <- function(nc, npar) {
#'   theta0  <- array(dim = c(nc, npar))  
#'   theta0[,2] <- runif(nc, 0, 10);   # b
#'   theta0[,1] <- runif(nc, 0, theta0[,2]); # A
#'   theta0[,3] <- runif(nc, 0, 7);   # v1
#'   theta0[,4] <- runif(nc, 0, 7);   # v2
#'   theta0[,5] <- runif(nc, 0, .5)   # t0           
#'   return(theta0)
#' }
#' 
#' npar <- 5 
#' nc   <- npar * 1 
#' theta0  <- init(nc, npar)
#' gamma <- cpda::gammavec(npar, 2.38)
#'   
#' ## Current chain index is 0 (C-based index)
#' crossover(theta0, gamma, 0)
#' crossover(theta0, gamma, 1)
#' crossover(theta0, gamma, 2)
#' crossover(theta0, gamma, 3)
#' crossover(theta0, gamma, 4)
#' 
#' migration(theta0, gamma, 4)
#' get_subchains(nc)
#' 
crossover <- function(theta, gammamult = 2.38, rp = 0.001) {
    .Call('cpda_crossover', PACKAGE = 'cpda', theta, gammamult, rp)
}

#' @rdname crossover
#' @export
getsubchains <- function(nchain) {
    .Call('cpda_getsubchains', PACKAGE = 'cpda', nchain)
}

#' @rdname crossover
#' @export
migration <- function(theta, gammamult = 2.38, rp = 0.001) {
    .Call('cpda_migration', PACKAGE = 'cpda', theta, gammamult, rp)
}

#' Generate Random Choice Response Times Using LBA Model
#'
#' This function uses two-accumulator LBA model to generate random choice RTs.
#'
#' \itemize{
#' \item \bold{\emph{b1}} response threshold for accumulator 1.
#' \item \bold{\emph{b2}} response threshold for accumulator 2.
#' \item \bold{\emph{A1}} starting point interval for accumulator 1.
#' \item \bold{\emph{A2}} starting point interval for accumulator 2.
#' \item \bold{\emph{mu1}} drift rate for accumulator 1.
#' \item \bold{\emph{mu2}} drift rate for accumulator 2.
#' \item \bold{\emph{sigma1}} drift rate standard deviation for accumulator 1.
#' \item \bold{\emph{sigma2}} drift rate standard deviation for accumulator 2.
#' \item \bold{\emph{t01}} non-decision time for accumulator 1.
#' \item \bold{\emph{t02}} non-decision time for accumulator 2.
#' }
#'
#' @param n number of observations. Must be an integer
#' @param pVec a two-accumulator LBA parameter vector. The sequence is
#' critical. It is, b1, b2, A1, A2, mu1, mu2, sigma1, sigma2, t01, and t02.
#' @return A matrix. First column stores choices and second column stores RTs
#' in seconds
#' @export
#' @examples
#' n    <- 10
#' pVec <- c(b1=1, b2=1, A1=.5, A2=.5, mu1=2.4, mu2=1.6, sigma1=1, sigma2=1.2,
#'           t01=.5, t02=.5)
#' dat1 <- cpda::rlba(n, pVec)
#' str(dat1)
#' summary(dat1)
#'
#' pVec <- c(b=1, A=.5, v1=2.4, v2=1.6, sv1=1, sv2=1.2, t0=.5)
#' dat1 <- cpda::rlba1(n, pVec)
#'
#' ## Compare to rtdists
#' ## dat2 <- rtdists::rLBA(n, A=0.5, b=1, t0 = 0.5, mean_v=c(2.4, 1.6),
#' ## sd_v=c(1,1.2))
#' ## str(dat2)
#' ## summary(dat2)
#'
rlba <- function(n, pVec) {
    .Call('cpda_rlba', PACKAGE = 'cpda', n, pVec)
}

#' @export
rlba_internal <- function(n, b, A, mean_v, sd_v, t0) {
    .Call('cpda_rlba_internal', PACKAGE = 'cpda', n, b, A, mean_v, sd_v, t0)
}

#' @export
n1PDF <- function(RT0, b, A, mean_v, sd_v, t0, nsim = 1e6L, debug = TRUE) {
    .Call('cpda_n1PDF', PACKAGE = 'cpda', RT0, b, A, mean_v, sd_v, t0, nsim, debug)
}

#' @export
rlba1 <- function(n, pVec) {
    .Call('cpda_rlba1', PACKAGE = 'cpda', n, pVec)
}

#' @rdname rplba
#' @export
rplba1 <- function(n, pVec) {
    .Call('cpda_rplba1', PACKAGE = 'cpda', n, pVec)
}

#' @rdname rplba
#' @export
rplba2 <- function(n, pVec) {
    .Call('cpda_rplba2', PACKAGE = 'cpda', n, pVec)
}

#' Generate Random Choice Response Times using pLBA Model
#'
#' This function uses two-accumulator piecewise LBA model to generate random
#' choice RTs. There are 3 variants: \code{rplba}, \code{rplba1}, and
#' \code{rplba2}. Each of them has a corresponding R version,
#' \code{rplbaR}, \code{rplbaR1}, and \code{rplbaR2}, for the purpose of
#' speed testing. Because the difference of random number generators in C and
#' R, they do not generate exactly identical RTs.  When generating large
#' enough observations, the distributions generated by R and C will match.
#'
#' The main function \code{rplba} implements a more flexible
#' version of pLBA random number generator than the other two. It uses the
#' following parameterisation (order matter):
#'
#' \itemize{
#' \item \bold{\emph{A1}} accumulator 1 start-point upper bound. \code{A} is
#' the upper bound of the interval \code{[0, A]}, which is used by an uniform
#' distribution to generate a start-point. Average amount of
#' prior evidence (i.e., before accumulation process even begins) across trials
#' is \code{A/2}.
#' \item \bold{\emph{A2}} accumulator 2 start-point upper bound.
#' \item \bold{\emph{B1}} accumulator 1 traveling distance. Note this is not
#' a decision threshold!. LBA convention denotes decision threshold/caution as
#' b (lowercase) and traveling distance as B (uppercase). \code{B=b-A} is
#' the traveling distance, and \code{b-A/2} is a measure of average
#' \emph{decision caution}.
#' \item \bold{\emph{B2}} accumulator 2 traveling distance.
#' \item \bold{\emph{C1}} the amount of traveling distance change for
#' accumulator 1 at the stage 2.
#' \item \bold{\emph{C2}} the amount of traveling distance change for
#' accumulator 2 at the stage 2.
#' \item \bold{\emph{v1}} accumulator 1 drift rate, stage 1
#' \item \bold{\emph{v2}} accumulator 2 drift rate, stage 1
#' \item \bold{\emph{w1}} accumulator 1 drift rate, stage 2
#' \item \bold{\emph{w2}} accumulator 2 drift rate, stage 2
#' \item \bold{\emph{sv1}} accumulator 1 drift rate standard deviation,
#' stage 1.
#' \item \bold{\emph{sv2}} accumulator 2 drift rate standard deviation,
#' stage 1.
#' \item \bold{\emph{sw1}} accumulator 1 drift rate standard deviation,
#' stage 2.
#' \item \bold{\emph{sw2}} accumulator 2 drift rate standard deviation,
#' stage 2.
#' \item \bold{\emph{rD}} the delay duration while stage 1 drift rate switches
#' to stage 2 drift rate
#' \item \bold{\emph{tD}} the delay duration while stage 1 threshold switches
#' to stage 2 threshold
#' \item \bold{\emph{swt}} switch time, usually determined by experimental
#' design.
#' \item \bold{\emph{t0}} non-decision time in second.
#' }
#'
#' \code{rplba1} uses the following parameterisation:
#'
#' \itemize{
#' \item \bold{\emph{A}} a common start-point interval for both accumulators.
#' \item \bold{\emph{b}} a common response threshold for both accumulators.
#' \item \bold{\emph{v1}} accumulator 1 drift rate, stage 1
#' \item \bold{\emph{v2}} accumulator 2 drift rate, stage 1
#' \item \bold{\emph{w1}} accumulator 1 drift rate, stage 2
#' \item \bold{\emph{w2}} accumulator 2 drift rate, stage 2
#' \item \bold{\emph{sv}} a common standard deviation for both accumulators
#' \item \bold{\emph{rD}} a delay period while drift rate switch to a
#' second stage process
#' \item \bold{\emph{swt}} switch time, usually determined by experimental
#' design
#' \item \bold{\emph{t0}} non-decision time in second.
#' }
#'
#' \code{rplba2} uses the following parameterisation:
#'
#' \itemize{
#' \item \bold{\emph{A1}} start-point interval of the accumulator 1.
#' \item \bold{\emph{A2}} start-point interval of the accumulator 2.
#' \item \bold{\emph{b1}} accumulator 1 response threshold.
#' \item \bold{\emph{b2}} accumulator 2 response threshold.
#' \item \bold{\emph{v1}} accumulator 1 drift rate, stage 1
#' \item \bold{\emph{v2}} accumulator 2 drift rate, stage 1
#' \item \bold{\emph{w1}} accumulator 1 drift rate, stage 2
#' \item \bold{\emph{w2}} accumulator 2 drift rate, stage 2
#' \item \bold{\emph{sv1}} the standard deviation of accumulator 1 drirt rate
#' during stage 1.
#' \item \bold{\emph{sv2}} the standard deviation of accumulator 2 drirt rate
#' during stage 1.
#' \item \bold{\emph{sw1}} the standard deviation of accumulator 1 drirt rate
#' during stage 2.
#' \item \bold{\emph{sw2}} the standard deviation of accumulator 2 drirt rate
#' during stage 2.
#' \item \bold{\emph{rD}} a delay period while drift rate switch to a
#' second stage process
#' \item \bold{\emph{swt}} switch time, usually determined by experimental
#' design
#' \item \bold{\emph{t0}} non-decision time in second.
#' }
#'
#' @param n number of observations. Must be an integer
#' @param pVec a numeric vector storing pLBA model parameters. The sequence is
#' critical. See details for the sequence.
#' @return A \code{n x 2} matrix with a first column storing choices and second
#' column storing response times.
#' @export
#' @examples
#' ################
#' ## Example 1  ##
#' ################
#' pVec3.1 <- c(A1=1.51, A2=1.51, B1=1.2, B2=1.2, C1=.3, C2=.3, v1=3.32,
#'              v2=2.24, w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.1,
#'              tD=.1, swt=0.5, t0=0.08)
#' pVec3.2 <- c(A1=1.51, A2=1.51, B1=1.2, B2=1.2, C1=.3, C2=.3, v1=3.32,
#'              v2=2.24, w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.1,
#'              tD=.15, swt=0.5, t0=0.08)
#' pVec3.3 <- c(A1=1.51, A2=1.51, B1=1.2, B2=1.2, C1=.3, C2=.3, v1=3.32,
#'              v2=2.24, w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.15,
#'              tD=.1, swt=0.5, t0=0.08)
#'
#' n <- 1e5
#' set.seed(123); system.time(dat5.1 <- cpda::rplbaR(n, pVec3.1))
#' set.seed(123); system.time(dat5.2 <- cpda::rplbaR(n, pVec3.2))
#' set.seed(123); system.time(dat5.3 <- cpda::rplbaR(n, pVec3.3))
#' set.seed(123); system.time(dat6.1 <- cpda::rplba( n, pVec3.1))
#' set.seed(123); system.time(dat6.2 <- cpda::rplba( n, pVec3.2))
#' set.seed(123); system.time(dat6.3 <- cpda::rplba( n, pVec3.3))
#' tmp5.1 <- data.frame(choice=factor(dat5.1[,1]), rt=dat5.1[,2])
#' tmp5.2 <- data.frame(choice=factor(dat5.2[,1]), rt=dat5.2[,2])
#' tmp5.3 <- data.frame(choice=factor(dat5.3[,1]), rt=dat5.3[,2])
#' tmp6.1 <- data.frame(choice=factor(dat6.1[,1]), rt=dat6.1[,2])
#' tmp6.2 <- data.frame(choice=factor(dat6.2[,1]), rt=dat6.2[,2])
#' tmp6.3 <- data.frame(choice=factor(dat6.3[,1]), rt=dat6.3[,2])
#'
#' tmp5.1$fun <- "R"
#' tmp5.2$fun <- "R"
#' tmp5.3$fun <- "R"
#' tmp6.1$fun <- "C"
#' tmp6.2$fun <- "C"
#' tmp6.3$fun <- "C"
#'
#' tmp5.1$vec <- "1"
#' tmp5.2$vec <- "2"
#' tmp5.3$vec <- "3"
#' tmp6.1$vec <- "1"
#' tmp6.2$vec <- "2"
#' tmp6.3$vec <- "3"
#'
#' df <- rbind(tmp5.1, tmp5.2, tmp5.3, tmp6.1, tmp6.2, tmp6.3)
#' df$fun <- factor(df$fun)
#'
#' ## Show R and C functions produce almost identical distributions
#' \dontrun{
#' ## Set up a colour palette
#' cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2",
#'         "#D55E00", "#CC79A7")
#'
#' require(ggplot2)
#' ggplot(data=df, aes(x = rt, fill=fun, color=fun)) +
#'   geom_density(alpha=0.2) +
#'   facet_grid(vec~ choice) +
#'   scale_fill_manual(values=cb)
#'
#' ## Or you can use lattice or base graphics
#' require(lattice)
#' histogram( ~rt | vec+choice+fun, data=df, breaks="fd", type="density",
#'            xlab="Response Time (s)",
#'            panel=function(x, ...) {
#'                  panel.histogram(x, ...)
#'                  panel.densityplot(x, darg=list(kernel="gaussian"),...)
#'   })
#' }
#'
#' par(mfrow=c(3,2))
#' hist(tmp5.1[tmp5.1$choice==1,"rt"], breaks="fd", col="gray", freq=FALSE,
#'        xlab="RT (s)", main="pLBA-Choice 1")
#' lines(density(tmp6.1[tmp6.1$choice==1,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'
#' hist(tmp5.1[tmp5.1$choice==2,"rt"], breaks="fd", col="gray", freq=FALSE,
#'        xlab="RT (s)", main="pLBA-Choice 2")
#' lines(density(tmp6.1[tmp6.1$choice==2,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'
#' #############
#' hist(tmp5.2[tmp5.2$choice==1,"rt"], breaks="fd", col="gray", freq=FALSE,
#'        xlab="RT (s)", main="pLBA-Choice 1")
#' lines(density(tmp6.2[tmp6.2$choice==1,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'
#' hist(tmp5.2[tmp5.2$choice==2,"rt"], breaks="fd", col="gray", freq=FALSE,
#'          xlab="RT (s)", main="pLBA-Choice 2")
#' lines(density(tmp6.2[tmp6.2$choice==2,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'
#' #############
#' hist(tmp5.3[tmp5.3$choice==1,"rt"], breaks="fd", col="gray", freq=FALSE,
#'          xlab="RT (s)", main="pLBA-Choice 1")
#' lines(density(tmp6.3[tmp6.3$choice==1,"rt"]), col="red", lty="dashed",  lwd=1.5)
#'
#' hist(tmp5.3[tmp5.3$choice==2,"rt"], breaks="fd", col="gray", freq=FALSE,
#'            xlab="RT (s)", main="pLBA-Choice 2")
#' lines(density(tmp6.3[tmp6.3$choice==2,"rt"]), col="red", lty="dashed",  lwd=1.5)
#' par(mfrow=c(1,1))
#'
#' ################
#' ## Example 2  ##
#' ################
#' pVec1 <- c(A=1.51, b=2.7, v1=3.32, v2=2.24,  w1=1.51,  w2=3.69,
#'            sv=1, rD=0.31, swt=0.5, t0=0.08)
#'
#' pVec2 <- c(A1=1.51, A2=1.51, b1=2.7, b2=2.7, v1=3.32, v2=2.24,
#'            w1=1.51, w2=3.69, sv1=1, sv2=1, sw1=1, sw2=1, rD=0.31,
#'            swt=0.5, t0=0.08)
#'
#' system.time(dat1 <- cpda::rplba1( n, pVec1))
#' system.time(dat2 <- cpda::rplba2( n, pVec2))
#' system.time(dat3 <- cpda::rplbaR1(n, pVec1))
#' system.time(dat4 <- cpda::rplbaR2(n, pVec2))
#'
#' tmp1 <- data.frame(choice=factor(dat1[,1]), rt=dat1[,2])
#' tmp2 <- data.frame(choice=factor(dat2[,1]), rt=dat2[,2])
#' tmp3 <- data.frame(choice=factor(dat3[,1]), rt=dat3[,2])
#' tmp4 <- data.frame(choice=factor(dat4[,1]), rt=dat4[,2])
#' tmp1$fun <- "rplba1"
#' tmp2$fun <- "rplba2"
#' tmp3$fun <- "rplba1-R"
#' tmp4$fun <- "rplba2-R"
#' tmp0 <- rbind(tmp1, tmp2, tmp3, tmp4)
#' tmp0$fun <- factor(tmp0$fun)
#'
#' \dontrun{
#' require(ggplot2)
#' ggplot(data = tmp0, aes(x = rt, fill=fun, color=fun)) +
#'     geom_density(alpha=0.2) +
#'     facet_grid(.~ choice) +
#'     scale_fill_manual(values=cb)
#' }
#'
rplba <- function(n, pVec) {
    .Call('cpda_rplba', PACKAGE = 'cpda', n, pVec)
}

#' @rdname rplba
#' @export
rplba3 <- function(n, pVec) {
    .Call('cpda_rplba3', PACKAGE = 'cpda', n, pVec)
}

#' @rdname rplba
#' @export
rplba4 <- function(n, pVec) {
    .Call('cpda_rplba4', PACKAGE = 'cpda', n, pVec)
}

#' @export
rplba5 <- function(n, pVec) {
    .Call('cpda_rplba5', PACKAGE = 'cpda', n, pVec)
}

#' @export
rplba6 <- function(n, pVec) {
    .Call('cpda_rplba6', PACKAGE = 'cpda', n, pVec)
}

#' Calculate edges for simulated histogram 
#'
#' This is an internal function. The user may not use it.
#' 
#' @param z a grid a scalar, usually created by 
#' \code{z = arma::linspace<arma::vec>(z0, z1, 1<<(int)p);}
#' 
#' @export
getEdges <- function(z) {
    .Call('cpda_getEdges', PACKAGE = 'cpda', z)
}

#' @export
getFilter <- function(m, M, h, p) {
    .Call('cpda_getFilter', PACKAGE = 'cpda', m, M, h, p)
}

#' Compute Summed Log-Likelihood Using KDE-FFT
#'
#' This function uses KDE-FFT method to approximate probability density.
#' \code{logLik_fft} returns only one scalar value, which is summed, logged
#' likelihood.
#'
#' @param y a vector storing empirical data.
#' @param yhat a vector storing simulated data (e.g., \code{rnorm(100)}).
#' @param h the bandwidth of kernel density estimation. If not given,
#' \code{logLik_fft} will detect the default, \code{h==0} and accordingly
#' convert it to Sliverman's rule of thumb; otherwise the function uses
#' bandwidth entered by the user.
#' @param m a multiplier to adjust \code{h} proportationally. Default is 0.8.
#' If one wish not adjust bandwidth, s/he has to enter \code{m=1}.
#' @param p a precision parameter defines the number of grid as power of 2.
#' Default value is 10 (i.e., ngrid==2^10).
#' @param n the number of simulation. When n=0, where the function will count
#' the numbers of observation in the simulated histogram. If simulating 
#' a defective distribution, one should enter the total number of simulation. 
#' @return Summed, logged likelihood
#' @references Holmes, W. (2015). A practical guide to the Probability Density
#' Approximation (PDA) with improved implementation and error characterization.
#' \emph{Journal of Mathematical Psychology}, \bold{68-69}, 13--24,
#' doi: http://dx.doi.org/10.1016/j.jmp.2015.08.006.
#' @seealso
#' \code{\link{bw.nrd}}, \code{\link{logLik_fft2}},
#' \code{\link{bandwidth.nrd}}.
#'
#' @export
#' @examples
#' ## See logLik_fft2 for more examples
#' ## Use piecewise LBA data as an example
#' data(lba)
#' logLik_fft(plba$DT1, plba$eDT1)
#' logLik_fft(plba$DT2, plba$eDT2)
logLik_fft <- function(y, yhat, h = 0, m = 0.8, p = 10, n = 0L) {
    .Call('cpda_logLik_fft', PACKAGE = 'cpda', y, yhat, h, m, p, n)
}

#' Compute Likelihood, using FFT method
#'
#' \code{lik_fft2} uses an identical algorithm as \code{logLik_fft}, but
#' return a matrix. Differing from \code{lik_pw}, \code{lik_fft2}
#' and \code{logLik_fft},
#' \enumerate{
#' \item takes Monte Carlo simulations,
#' \item transforms them to spectral domain using FFT,
#' \item applies a standard Gaussian kernel to smooth them,
#' \item transforms them back to signal domain and
#' \item interpolates linearly the simulation histogram to the observation 
#' to obtain estimated likelihoods.
#' }
#'
#' @param y a vector storing empirical data.
#' @param yhat a vector storing simulated data (e.g., \code{rnorm(100)}).
#' @param h the bandwidth for kernel density estimation. If not given,
#' \code{Lik_fft2} will use Sliverman's rule of thumb
#' @param m a multiplier to adjust \code{h} proportationally. Default is 0.8.
#' This applies also when the user enters his/her own bandwidth.
#' @param p a precision parameter defines the number of grid as power of 2.
#' Default value is 10 (i.e., 2^10).
#' @param n the number of simulation. When n=0, where the function will count
#' the numbers of observation in the simulated histogram. If simulating 
#' a defective distribution, one should enter the simulation numbers. 
#' @return A n x 2 matrix. Keep original order without sorting.
#' @references Holmes, W. (2015). A practical guide to the Probability Density
#' Approximation (PDA) with improved implementation and error characterization.
#' \emph{Journal of Mathematical Psychology}, \bold{68-69}, 13--24,
#' doi: http://dx.doi.org/10.1016/j.jmp.2015.08.006.
#' @seealso
#' \code{\link{logLik_pw}}, \code{\link{logLik_fft}},
#' \code{\link{bw.nrd}}, \code{\link{bandwidth.nrd}}.
#'
#' @export
#' @examples
#' ###################
#' ## Example 1     ##
#' ###################
#' x <- seq(-3, 3, length.out=100) ## Data
#' samp <- rnorm(1e5)              ## Monte Carlo simulation
#' h <- 0.8*bw.nrd0(samp)          ## Define bandwidth using R's bw.nrd0
#'
#' ## point-wise and fft
#' pw1  <- lik_pw(x, samp, h=h, m=1)
#' fft1 <- lik_fft(x, samp, h=h, m=1)
#'
#' ## the tails may be a bit off.
#' plot(x, pw1, type="l", lty="dotted")
#' lines(x, fft1[,2], col="darkgreen", lty="dashed")
#' lines(x, dnorm(x), col="red", lwd=2)
#'
#' ###################
#' ## Example 2     ##
#' ###################
#' rm(list=ls())
#' ## Assuming that this is empirical data
#' y <- rtdists::rLBA(1e3, A=.5, b=1, t0=.25, mean_v=c(2.4, 1.2), sd_v=c(1,1))
#' rt1  <- y[y$response==1,"rt"]
#' rt2  <- y[y$response==2,"rt"]
#' srt1 <- sort(rt1)
#' srt2 <- sort(rt2)
#' 
#' xlabel <- "RT"; ylabel <- "Density"
#' par(mfrow=c(1,2))
#' hist(rt1, "fd", freq=F, xlim=c(0.1,1.5), main="Choice 1", 
#'     xlab=xlabel, ylab=ylabel)
#' hist(rt2, "fd", freq=F, xlim=c(0.1,1.5), main="Choice 2",
#'     xlab=xlabel, ylab=ylabel)
#' par(mfrow=c(1,1))
#' 
#' ## Now draw simulations from another rLBA
#' n <- 1e5
#' samp <- rtdists::rLBA(n, A=.5, b=1, t0=.25, mean_v=c(2.4, 1.2), sd_v=c(1,1))
#' samp1 <- samp[samp[,2]==1, 1]
#' samp2 <- samp[samp[,2]==2, 1]
#' fft1 <- lik_fft(srt1, samp1, n=n)[,2]
#' fft2 <- lik_fft(srt2, samp2, n=n)[,2]
#' 
#' ## Just another way to simulate. This is to compare with gpda
#' pvec <- c(b=1, A=.5, v1=2.4, v2=1.2, sv1=1, sv2=1, t0=.25)
#' samp <- cpda::rlba1(n, pvec)
#' samp1 <- samp[samp[,2]==1, 1]
#' samp2 <- samp[samp[,2]==2, 1]
#' fft3 <- lik_fft(srt1, samp1, n=n)[,2]
#' fft4 <- lik_fft(srt2, samp2, n=n)[,2]
#' 
#' ## Calculate theoretical densities
#' den0 <- rtdists::dLBA(y$rt, y$response, A=.5, b=1, t0=.25, 
#'    mean_v=c(2.4, 1.2), sd_v=c(1, 1))
#'    
#' df0 <- cbind(y, den0)
#' df1 <- df0[df0[,2]==1,]
#' df2 <- df0[df0[,2]==2,]
#' den1 <- df1[order(df1[,1]),3]
#' den2 <- df2[order(df2[,1]),3]
#' plot(srt1,  den1, type="l")
#' lines(srt2, den2)
#' lines(srt1, fft1, col="red")
#' lines(srt2, fft2, col="red")
#' lines(srt1, fft3, col="blue")
#' lines(srt2, fft4, col="blue")
#'
lik_fft <- function(y, yhat, h = 0, m = 0.8, p = 10, n = 0L) {
    .Call('cpda_lik_fft', PACKAGE = 'cpda', y, yhat, h, m, p, n)
}

#' Point-wise Probability Density Approximation
#'
#' \code{lik_pw} takes each observation and sequentially (or concurrently)
#' via Open MP) conduct KDEs. This function is for testing purpose. If you 
#' wish to conduct KDE smoothing point-by-point, use 'density'
#' in \code{stats}, which uses a similar FFT algorithm as \code{lik_fft}. 
#'
#' @param y a vector storing empirical observations (e.g., RTs).
#' @param yhat a vector storing simulations.
#' @param h kernel bandwidth. Default value is 0.8 times Silverman's Rule of
#' Thumb, based on simulated data (i.e., yhat).
#' @param m a bandwidth multiplier. Default is 0.8.
#' @param n the number of simulation. When n=0, where the function will count
#' the numbers of observation in the simulated histogram. If simulating 
#' a defective distribution, one should enter the simulation numbers. 
#' @param parallel a switch for parallel processing via OMP. Default is FALSE. 
#' @return a vector storing log-likelihoods
#' @references 
#' Holmes, W. (2015). A practical guide to the Probability Density
#' Approximation (PDA) with improved implementation and error characterization.
#' \emph{Journal of Mathematical Psychology}, vol. 68-69, 13--24,
#' doi: \url{http://dx.doi.org/10.1016/j.jmp.2015.08.006}. \cr
#' 
#' Turner, B. M. & Sederberg, P. B. (2014). A generalized, likelihood-free 
#' method for posterior estimation. \emph{Psychonomic Bulletin Review}, 21(2), 
#' 227-250. doi: \url{http://dx.doi.org/10.3758/s13423-013-0530-0}. \cr
#' 
#' Brown, S. & Heathcote, A. (2008). The simplest complete model of choice 
#' response time: Linear ballistic accumulation. \emph{Cognitive Psychology}, 
#' 57, 153-178. doi: \url{http://dx.doi.org/10.1016/j.cogpsych.2007.12.002}.
#' @export
#' @examples
#' ## Example 1 tests if Lik_pw match 'dnorm' and shows how to adjust 
#' ## bandwidth  
#' rm(list=ls())
#' lik_pw(0, rnorm(1e6)) ## 0.3974386
#' dnorm(0)              ## 0.3989423
#'
#' h <- 0.8*bw.nrd0(rnorm(1e6));            ## 0.04542646 
#' lik_pw(0, rnorm(1e6), h=h)      ## 0.3996198
#' lik_pw(0, rnorm(1e6), h=h, m=1) ## 0.3985692
#'
#' ## Example 2 demostrates how to use Lik_pw to get pLBA likelihoods
#' data(lba)
#' str(plba)
#' ## List of 4
#' ## $ DT1 : num [1:695] 0.488 0.801 0.376 0.507 0.532 ...
#' ## $ DT2 : num [1:305] 0.538 0.77 0.568 0.271 0.881 ...
#' ## $ eDT1: num [1:7020] 0.475 0.346 0.42 0.401 0.368 ...
#' ## $ eDT2: num [1:2980] 0.703 0.693 0.704 0.462 0.468 ...
#'
#' ## Use pointwise pda to get likelihoods for each data point
#' ## This algorithm calculates via a standard gaussian kernel directly
#' ## (1) First argument, plba$DT1, is the data.
#' ## (2) Second argument, plba$eDT1, is the simulation.
#' ## (3) The output is likelihood.
#'
#' output <- lik_pw(plba$DT1, plba$eDT1)
#' sum(output) ## Get summed, logged likelihood
#'
#' #########################
#' ## Example 3           ##
#' #########################
#' rm(list=ls())
#' n      <- 1e5
#' x      <- seq(-3,3, length.out=100) ## Support
#' xlabel <- "Observations" 
#' ylabel <- "Density" 
#' 
#' ## Approximate Gaussian densities
#' samp <- rnorm(n)
#' pw1  <- lik_pw(x, samp)
#' pw2  <- approx(density(samp)$x, density(samp)$y, x)$y
#' plot(x,  pw1, type="l", lty="longdash", xlab=xlabel, ylab=ylabel)
#' lines(x, pw2, lwd=1.5, lty="dotted")
#' lines(x, dnorm(x), lwd=2)
#' 
#' samp <- gamlss.dist::rexGAUS(n, mu=-2, sigma=1, nu=1)
#' system.time(pw1 <- lik_pw(x, samp, parallel=TRUE))
#' system.time(pw2 <- approx(density(samp)$x, density(samp)$y, x)$y)
#' plot(x,  pw1, type="l", lty="longdash", xlab=xlabel, ylab=ylabel)
#' lines(x, pw2, lwd=1.5, lty="dotted")
#' lines(x, gamlss.dist::dexGAUS(x, mu=-2, sigma=1, nu=1), col="red")
#'
#' ## Approximate densities of linear regression with Gaussian noise: 
#' ## y = ax + b + N(0, s)
#' theta <- c(a=7.5, b=3.5, s=5)
#' y     <- rnorm(length(x), mean=theta[2]+theta[1]*x, sd=theta[3])
#' dat   <- cbind(x, y)
#' plot(x, y, main="Linear Regression")
#' 
#' ## -- Because means for each data point differ, we need to generate 
#' ## simulation (ie samp) for each data point. That is, the likelihood for  
#' ## each data point is calculated by different simulated likelihood functions
#' ## -- We use sapply to gain a little speedy up. 
#' ## -- 'density' function cannot calculate density for only 1 data point 
#' pw1 <- sapply(x, function(s) {
#'   samp  <- rnorm(n, mean=theta[2]+theta[1]*s, sd=theta[3])
#'   lik_pw(s, samp)
#' })
#' plot(x,  pw1,  type="l", lty="longdash", xlab=xlabel, ylab=ylabel)
#' lines(x,  dnorm(x, theta[2]+theta[1]*x, theta[3]), col="red")
#' 
#' #########################
#' ## Example 4: LBA      ##
#' #########################
#' rm(list=ls())
#' ## Assuming that this is empirical data
#' y    <- rtdists::rLBA(1e3, A=.5, b=1, t0=.25, mean_v=c(2.4, 1.2), sd_v=c(1,1.2))
#' rt1  <- y[y$response==1,"rt"]
#' rt2  <- y[y$response==2,"rt"]
#' srt1 <- sort(rt1)
#' srt2 <- sort(rt2)
#' summary(rt1); summary(rt2)
#'     
#' n <- 1e5
#' pvec <- c(b=1, A=.5, v1=2.4, v2=1.2, sv1=1, sv2=1.2, t0=.25)
#' samp <- cpda::rlba1(n, pvec)
#' samp1 <- samp[samp[,2]==1, 1]
#' samp2 <- samp[samp[,2]==2, 1]
#' pw1 <- lik_pw(srt1, samp1, n=n)
#' pw2 <- lik_pw(srt2, samp2, n=n)
#'     
#' den0 <- rtdists::dLBA(y$rt, y$response, A=.5, b=1, t0=.25, 
#'   mean_v=c(2.4, 1.2), sd_v=c(1, 1.2))
#' df0 <- cbind(y, den0)
#' df1 <- df0[df0[,2]==1,]
#' df2 <- df0[df0[,2]==2,]
#' den1 <- df1[order(df1[,1]),3]
#' den2 <- df2[order(df2[,1]),3]
#'   
#' plot(srt1,  den1, type="l")
#' lines(srt2, den2)
#' lines(srt1, pw1, col="red")
#' lines(srt2, pw2, col="red")
#'     
#' #########################
#' ## Example 5           ##
#' #########################
#' n   <- 1e5
#' x   <- seq(-3,3, length.out=100) ## Support
#' sam <- rnorm(n)
#' 
#' ## Tested on 12-core CPU
#' rbenchmark::benchmark(replications=rep(10, 3),
#'    pw       <- cpda::lik_pw(x, sam),
#'    pw_omp   <- cpda::lik_pw(x, sam, parallel = T),
#'    columns=c('test', 'elapsed', 'replications'))
#' ##                                           test elapsed replications
#' ## 1                   pw <- cpda::lik_pw(x, sam)   2.570           10
#' ## 3                   pw <- cpda::lik_pw(x, sam)   2.485           10
#' ## 5                   pw <- cpda::lik_pw(x, sam)   2.484           10
#' ## 2 pw_omp <- cpda::lik_pw(x, sam, parallel = T)   0.993           10
#' ## 4 pw_omp <- cpda::lik_pw(x, sam, parallel = T)   1.119           10
#' ## 6 pw_omp <- cpda::lik_pw(x, sam, parallel = T)   1.024           10
#' 
#' @export
lik_pw <- function(y, yhat, h = 0, m = 0.8, n = 0L, parallel = 0L) {
    .Call('cpda_lik_pw', PACKAGE = 'cpda', y, yhat, h, m, n, parallel)
}

#' @export
logLik_lba <- function(y, pVec, n) {
    .Call('cpda_logLik_lba', PACKAGE = 'cpda', y, pVec, n)
}

#' @export
rtn_arma <- function(n, mean, sd, lower, upper) {
    .Call('cpda_rtn_arma', PACKAGE = 'cpda', n, mean, sd, lower, upper)
}

#' @export
pmax <- function(v, min) {
    .Call('cpda_pmax', PACKAGE = 'cpda', v, min)
}

#' A simple and fast quantile calculator
#'
#' A C++ quantile function.
#'
#' @param y a data vector
#' @param q nth quantile. Enter proportion, such as .25 or .75.
#' @examples
#' y <- rnorm(100)
#' q <- cquantile(y, .25)
#' @export
cquantile <- function(y, q) {
    .Call('cpda_cquantile', PACKAGE = 'cpda', y, q)
}

#' Silverman's Rule of Thumb Bandwidth for Kernel Density Estimation
#'
#' A C++ version of Silverman's rule-of-thumb bandwidth. This is similar
#' with R's \code{bw.nrd0(x)}
#'
#' @param y a data vector
#' @param m a multiplier to adjust the SROT proportionally.
#'
#' @seealso
#' \code{\link{bw.nrd}}, \code{\link{bandwidth.nrd}}.
#' @export
#' @examples
#' data(lba)
#' h <-cpda::bwNRD0(plba$DT1, 0.8)
#'
bwNRD0 <- function(y, m) {
    .Call('cpda_bwNRD0', PACKAGE = 'cpda', y, m)
}

#' @export
histc <- function(x, edge) {
    .Call('cpda_histc', PACKAGE = 'cpda', x, edge)
}

#' @export
histd <- function(yhat, z, n) {
    .Call('cpda_histd', PACKAGE = 'cpda', yhat, z, n)
}

