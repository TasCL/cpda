% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{beaumont_approximate_2010,
  Title                    = {Approximate {Bayesian} {Computation} in {Evolution} and {Ecology}},
  Author                   = {Beaumont, Mark A.},
  Journal                  = {Annual Review of Ecology, Evolution, and Systematics},
  Year                     = {2010},
  Number                   = {1},
  Pages                    = {379--406},
  Volume                   = {41},

  Abstract                 = {In the past 10years a statistical technique, approximate Bayesian computation (ABC), has been developed that can be used to infer parameters and choose between models in the complicated scenarios that are often considered in the environmental sciences. For example, based on gene sequence and microsatellite data, the method has been used to choose between competing models of human demographic history as well as to infer growth rates, times of divergence, and other parameters. The method fits naturally in the Bayesian inferential framework, and a brief overview is given of the key concepts. Three main approaches to ABC have been developed, and these are described and compared. Although the method arose in population genetics, ABC is increasingly used in other fields, including epidemiology, systems biology, ecology, and agent-based modeling, and many of these applications are briefly described.},
  Doi                      = {10.1146/annurev-ecolsys-102209-144621},
  File                     = {Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/AIEQE8JG/2010 - Approximate Bayesian Computation in Evolution and .pdf:application/pdf},
  Url                      = {http://dx.doi.org/10.1146/annurev-ecolsys-102209-144621},
  Urldate                  = {2017-03-09}
}

@Article{Braak2006,
  Title                    = {A Markov Chain Monte Carlo version of the genetic algorithm Differential Evolution: easy Bayesian computing for real parameter spaces},
  Author                   = {Braak, Cajo J. F. Ter},
  Journal                  = {Statistics and Computing},
  Year                     = {2006},
  Number                   = {3},
  Pages                    = {239--249},
  Volume                   = {16},

  __markedentry            = {[yslin:]},
  Abstract                 = {Differential Evolution (DE) is a simple genetic algorithm for numerical optimization in real parameter spaces. In a statistical context one would not just want the optimum but also its uncertainty. The uncertainty distribution can be obtained by a Bayesian analysis (after specifying prior and likelihood) using Markov Chain Monte Carlo (MCMC) simulation. This paper integrates the essential ideas of DE and MCMC, resulting in Differential Evolution Markov Chain (DE-MC). DE-MC is a population MCMC algorithm, in which multiple chains are run in parallel. DE-MC solves an important problem in MCMC, namely that of choosing an appropriate scale and orientation for the jumping distribution. In DE-MC the jumps are simply a fixed multiple of the differences of two random parameter vectors that are currently in the population. The selection process of DE-MC works via the usual Metropolis ratio which defines the probability with which a proposal is accepted. In tests with known uncertainty distributions, the efficiency of DE-MC with respect to random walk Metropolis with optimal multivariate Normal jumps ranged from 68{\%} for small population sizes to 100{\%} for large population sizes and even to 500{\%} for the 97.5{\%} point of a variable from a 50-dimensional Student distribution. Two Bayesian examples illustrate the potential of DE-MC in practice. DE-MC is shown to facilitate multidimensional updates in a multi-chain ``Metropolis-within-Gibbs'' sampling approach. The advantage of DE-MC over conventional MCMC are simplicity, speed of calculation and convergence, even for nearly collinear parameters and multimodal densities.},
  Doi                      = {10.1007/s11222-006-8769-1},
  ISSN                     = {1573-1375},
  Owner                    = {yslin},
  Timestamp                = {2017.03.10},
  Url                      = {http://dx.doi.org/10.1007/s11222-006-8769-1}
}

@Article{brown_simplest_2008,
  Title                    = {The simplest complete model of choice response time: linear ballistic accumulation},
  Author                   = {Brown, Scott D and Heathcote, Andrew},
  Journal                  = {Cognitive psychology},
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {153--178},
  Volume                   = {57},

  Doi                      = {doi:10.1016/j.cogpsych.2007.12.002},
  File                     = {ScienceDirect Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/PAGCKJUK/Brown and Heathcote - 2008 - The simplest complete model of choice response tim.pdf:application/pdf;ScienceDirect Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/Z3CRZ3DU/S0010028507000722.html:text/html;ScienceDirect Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/AB39NVMW/S0010028507000722.html:text/html},
  Keywords                 = {Choice, Decision, Lexical decision, Mathematical models, Reaction Time, Response time}
}

@Article{dawson_fitting_1988,
  Title                    = {Fitting the ex-{Gaussian} equation to reaction time distributions},
  Author                   = {Dawson, Michael R. W.},
  Journal                  = {Behavior Research Methods, Instruments, \& Computers},
  Year                     = {1988},

  Month                    = jan,
  Number                   = {1},
  Pages                    = {54--57},
  Volume                   = {20},

  Abstract                 = {Two programs that can be used to determine the probability distributions of reaction times are detailed. The first program takes rank-ordered reaction times as input and outputs a file of quantized data. The second program uses a simplex procedure to estimate the parameters of the ex-Gaussian equation that provides the best description of the quantized data. The advantages of this type of data analysis are also discussed.},
  Doi                      = {10.3758/BF03202603},
  File                     = {Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/9UD9V5AM/Dawson - 1988 - Fitting the ex-Gaussian equation to reaction time .pdf:application/pdf;Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/J6G2HBVQ/BF03202603.html:text/html},
  ISSN                     = {0743-3808, 1532-5970},
  Language                 = {en},
  Url                      = {https://link.springer.com/article/10.3758/BF03202603},
  Urldate                  = {2017-03-09}
}

@Book{gelman_bayesian_2014,
  Title                    = {Bayesian data analysis},
  Author                   = {Gelman, Andrew},
  Publisher                = {CRC Press},
  Year                     = {2014},

  Address                  = {Boca Raton},
  Note                     = {OCLC: 864304245},

  ISBN                     = {978-1-4398-4095-5 978-1-4398-4096-2},
  Language                 = {English}
}

@Article{hoffman2014_nut,
  Title                    = {The no-u-turn sampler: {Adaptively} setting path lengths in {Hamiltonian} {Monte} {Carlo}},
  Author                   = {Hoffman, Matthew D. and Gelman, Andrew},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2014},
  Number                   = {1},
  Volume                   = {15},

  Abstract                 = {Hierarchical Bayesian models are a mainstay of the machine learning and statistics communities. Exact posterior inference in such models is rarely tractable, so researchers and practitioners must usually resort to approximate inference methods. Perhaps the most popular class of approximate posterior inference algorithms, Markov Chain Monte Carlo (MCMC) methods offer schemes for},
  File                     = {Citeseer - Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/ZBVEJ72Z/Hoffman and Gelman - 2011 - The no-u-turn sampler Adaptively setting path len.pdf:application/pdf;Citeseer - Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/RSJW6ZFP/summary.html:text/html},
  Shorttitle               = {The no-u-turn sampler}
}

@Article{holmes_practical_2015,
  Title                    = {A practical guide to the {Probability} {Density} {Approximation} ({PDA}) with improved implementation and error characterization},
  Author                   = {Holmes, William R.},
  Journal                  = {Journal of Mathematical Psychology},
  Year                     = {2015},

  Month                    = oct,
  Pages                    = {13--24},
  Volume                   = {68--69},

  Abstract                 = {A critical task in modeling is to determine how well the theoretical assumptions encoded in a model account for observations. Bayesian methods are an ideal framework for doing just this. Existing approximate Bayesian computation (ABC) methods however rely on often insufficient “summary statistics”. Here, I present and analyze a highly efficient extension of the recently proposed (Turner and Sederberg 2014) Probability Density Approximation (PDA) method, which circumvents this insufficiency. This method combines Markov Chain Monte Carlo simulation with tools from non-parametric statistics to improve upon existing ABC methods. The primary contributions of this article are: (1) A more efficient implementation of this method that substantially improves computational performance is described. (2) Theoretical results describing the influence of methodological approximation errors on posterior estimation are discussed. In particular, while this method is highly accurate, even small errors have a strong influence on model comparisons when using standard statistical approaches (such as deviance information criterion). (3) An augmentation of the standard PDA procedure, termed “resampled PDA”, that reduces the negative influence of approximation errors on performance and accuracy, is presented. (4) A number of examples of varying complexity are presented along with supplementary code for their implementation.},
  Doi                      = {10.1016/j.jmp.2015.08.006},
  File                     = {ScienceDirect Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/K6GJHC6Z/Holmes - 2015 - A practical guide to the Probability Density Appro.pdf:application/pdf;ScienceDirect Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/2HKE7SKE/S0022249615000541.html:text/html},
  Keywords                 = {Approximate likelihood, Kernel density estimate, Linear ballistic accumulator model, Markov chain Monte Carlo, Non-parametric approximate Bayesian computation},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S0022249615000541},
  Urldate                  = {2017-01-09}
}

@Article{sanderson_armadillo:_2016,
  Title                    = {Armadillo: a template-based {C}++ library for linear algebra},
  Author                   = {Sanderson, Conrad and Curtin, Ryan},
  Journal                  = {The Journal of Open Source Software},
  Year                     = {2016},

  Month                    = jun,
  Number                   = {2},
  Volume                   = {1},

  Doi                      = {10.21105/joss.00026},
  Shorttitle               = {Armadillo},
  Url                      = {http://joss.theoj.org/papers/10.21105/joss.00026},
  Urldate                  = {2017-03-09}
}

@Book{silverman_density_1986,
  Title                    = {Density estimation for statistics and data analysis},
  Author                   = {Silverman, Bernard W},
  Publisher                = {CRC press},
  Year                     = {1986},
  Volume                   = {26}
}

@Article{sisson_likelihood_2010,
  Title                    = {Likelihood-free {Markov} chain {Monte} {Carlo}},
  Author                   = {Sisson, S. A. and Fan, Y.},
  Journal                  = {arXiv:1001.2058 [stat]},
  Year                     = {2010},

  Month                    = jan,
  Note                     = {arXiv: 1001.2058},

  Abstract                 = {To appear to MCMC handbook, S. P. Brooks, A. Gelman, G. Jones and X.-L. Meng (eds), Chapman \& Hall.},
  File                     = {arXiv\:1001.2058 PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/29ZWJNE5/Sisson and Fan - 2010 - Likelihood-free Markov chain Monte Carlo.pdf:application/pdf;arXiv.org Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/GQACJXXU/1001.html:text/html},
  Keywords                 = {Statistics - Methodology},
  Url                      = {http://arxiv.org/abs/1001.2058},
  Urldate                  = {2017-03-09}
}

@Article{Turner2013,
  Title                    = {Likelihood-free {Bayesian} analysis of memory models},
  Author                   = {Turner, Brandon M. and Dennis, Simon and Van Zandt, Trisha},
  Journal                  = {Psychological Review},
  Year                     = {2013},
  Number                   = {3},
  Pages                    = {667--678},
  Volume                   = {120},

  __markedentry            = {[yslin:6]},
  Abstract                 = {Many influential memory models are computational in the sense that their predictions are derived through simulation. This means that it is difficult or impossible to write down a probability distribution or likelihood that characterizes the random behavior of the data as a function of the model’s parameters. In turn, the lack of a likelihood means that these models cannot be directly fitted to data using traditional techniques. In particular, standard Bayesian analyses of such models are impossible. In this article, we examine how a new procedure called approximate Bayesian computation (ABC), a method for Bayesian analysis that circumvents the evaluation of the likelihood, can be used to fit computational models to memory data. In particular, we investigate the bind cue decide model of episodic memory (Dennis \& Humphreys, 2001) and the retrieving effectively from memory model (Shiffrin \& Steyvers, 1997). We fit hierarchical versions of each model to the data of Dennis, Lee, and Kinnell (2008) and Kinnell and Dennis (2012). The ABC analysis permits us to explore the relationships between the parameters in each model as well as evaluate their relative fits to data—analyses that were not previously possible.},
  Copyright                = {(c) 2016 APA, all rights reserved},
  Doi                      = {10.1037/a0032458},
  ISSN                     = {1939-1471 0033-295X},
  Keywords                 = {*Computational Modeling, *Memory, *Models, *Simulation, Statistical Probability},
  Language                 = {English},
  Owner                    = {yslin},
  Timestamp                = {2017.03.10}
}

@Article{turner_generalized_2014,
  Title                    = {A generalized, likelihood-free method for posterior estimation},
  Author                   = {Turner, Brandon M. and Sederberg, Per B.},
  Journal                  = {Psychonomic Bulletin \& Review},
  Year                     = {2014},

  Month                    = apr,
  Number                   = {2},
  Pages                    = {227--250},
  Volume                   = {21},

  Abstract                 = {Recent advancements in Bayesian modeling have allowed for likelihood-free posterior estimation. Such estimation techniques are crucial to the understanding of simulation-based models, whose likelihood functions may be difficult or even impossible to derive. However, current approaches are limited by their dependence on sufficient statistics and/or tolerance thresholds. In this article, we provide a new approach that requires no summary statistics, error terms, or thresholds and is generalizable to all models in psychology that can be simulated. We use our algorithm to fit a variety of cognitive models with known likelihood functions to ensure the accuracy of our approach. We then apply our method to two real-world examples to illustrate the types of complex problems our method solves. In the first example, we fit an error-correcting criterion model of signal detection, whose criterion dynamically adjusts after every trial. We then fit two models of choice response time to experimental data: the linear ballistic accumulator model, which has a known likelihood, and the leaky competing accumulator model, whose likelihood is intractable. The estimated posterior distributions of the two models allow for direct parameter interpretation and model comparison by means of conventional Bayesian statistics—a feat that was not previously possible.},
  Doi                      = {10.3758/s13423-013-0530-0},
  File                     = {Full Text PDF:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/HWE5B3X8/Turner and Sederberg - 2014 - A generalized, likelihood-free method for posterio.pdf:application/pdf;Snapshot:/home/yslin/.mozilla/firefox/dgi432js.default/zotero/storage/2D4UKPPC/s13423-013-0530-0.html:text/html},
  ISSN                     = {1069-9384, 1531-5320},
  Language                 = {en},
  Url                      = {https://link.springer.com/article/10.3758/s13423-013-0530-0},
  Urldate                  = {2017-03-09}
}

